{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "familiar-insert",
   "metadata": {},
   "source": [
    "## Movie review model generation\n",
    "This notebook handles the model generation for the movie review dataset.\n",
    "Before running this notebook, make sure to run the [data preparation notebook](./data_preparation.ipynb) to generate\n",
    "the word embeddings required for the model.  \n",
    "In addition to [PyTorch](https://pytorch.org/docs/stable/index.html), this notebook depends on [torchtext](https://pytorch.org/text/stable/index.html) for handling the input data. The notebook is also linked to [Weights & Biases](wandb.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "written-cambridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode = 'online'\n",
    "mode = 'disabled'\n",
    "wandb.init(project='movie-reviews', entity='dianna-ai', mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electronic-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable hyperparameters\n",
    "config = wandb.config\n",
    "config.batch_size = 256\n",
    "config.epochs = 20\n",
    "config.output_dim = 2\n",
    "config.dropout = .6913\n",
    "config.n_filters = 245\n",
    "config.filter_sizes = [3, 4, 5]\n",
    "config.learning_rate = 0.0005261\n",
    "config.weight_decay = 0.0005\n",
    "config.max_samples = 10000  # maximum samples of training set to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch will use cuda\n"
     ]
    }
   ],
   "source": [
    "# select device to run on\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch will use {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indian-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data files\n",
    "data_path = os.path.join(os.path.expanduser('~'), 'surfdrive/Shared/datasets/stanford_sentiment_treebank_v2')\n",
    "\n",
    "# tokenizer for splitting input sentences\n",
    "tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "\n",
    "# word vectors as generated from data preparation notebook\n",
    "vocab = Vectors('word_vectors.txt', cache='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "productive-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to hold a dataset\n",
    "# custom datasets need to implement init, len, and getitem\n",
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, filename, max_samples=None):\n",
    "        self.data = pd.read_csv(filename, delimiter='\\t')\n",
    "        if max_samples is not None:\n",
    "            self.data = self.data[:min(len(self.data), max_samples)]\n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "        # get sentence and corresponding label\n",
    "        sentence = self.data.iloc[idx]['sentence']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return sentence, label.astype(np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enclosed-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into PyTorch dataset\n",
    "# These datasets return the input as numerical values, suited for input to the model\n",
    "\n",
    "train_data = MovieReviewDataset(os.path.join(data_path, 'train.tsv'), max_samples=config.max_samples)\n",
    "val_data = MovieReviewDataset(os.path.join(data_path, 'validation.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "million-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators for the data\n",
    "batch_size = config.batch_size\n",
    "nworker = min(12, os.cpu_count() - 1)\n",
    "\n",
    "train_data_iterator = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=nworker, pin_memory=True)\n",
    "val_data_iterator = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=nworker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polar-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab, tokenizer, n_filters, filter_sizes, dropout, output_dim, device=None):\n",
    "        super().__init__()\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.device = device\n",
    "        \n",
    "        vocab_size, embedding_size = vocab.vectors.size()\n",
    "        self.padding_idx = vocab.stoi['<pad>']\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=self.padding_idx)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for filter_size in filter_sizes:\n",
    "            layer = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_size, embedding_size))\n",
    "            self.conv_layers.append(layer)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
    "        \n",
    "    def collate(self, tokens):\n",
    "        # get max sample size: each item in tokens is the input sentence split into numerical tokens\n",
    "        max_size = max(max(map(len, tokens)), max(self.filter_sizes))\n",
    "        # create input array with padding such that each element has the same size\n",
    "        input_data = np.empty((len(tokens), max_size), dtype=int)\n",
    "        for i, item in enumerate(tokens):\n",
    "            # pad each element and store numericalized tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>'] for token in item]\n",
    "            npad = max(max_size - len(item), 0)\n",
    "            input_data[i] = tokens_numerical + [self.padding_idx] * npad\n",
    "\n",
    "        # convert to tensors\n",
    "        input_data = torch.LongTensor(input_data)\n",
    "        if self.device is not None:\n",
    "            input_data = input_data.to(self.device)\n",
    "        return input_data\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # first split sentences into tokens\n",
    "        tokens = [self.tokenizer(sentence) for sentence in text]\n",
    "        # pad sentences so they all have the same length, convert tokens to numerical embedding, \n",
    "        # then make one big tensor for the entire batch of data\n",
    "        tokens = self.collate(tokens)\n",
    "        # shape = [batch size, max nword per sentence]\n",
    "        embedding = self.embedding(tokens).unsqueeze(1)\n",
    "        # shape = [batch_size, 1, nword, embedding dim]\n",
    "        conved = [F.relu(conv(embedding)).squeeze(3) for conv in self.conv_layers]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter, nword - filter_size + 1]\n",
    "        # note: max_pool1d does not work with ONNX when output shape is dynamic\n",
    "        # therefore switched to adaptive_max_pool1d\n",
    "        pooled = [F.adaptive_max_pool1d(out, 1).squeeze(2) for out in conved]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter]\n",
    "        concat = torch.cat(pooled, dim=1)\n",
    "        # shape = [batch_size * len(filter_sizes), n_filter]\n",
    "        dropped = self.dropout(concat)\n",
    "        return self.fc(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passive-character",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f5a002d9d30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init a model\n",
    "output_dim = config.output_dim\n",
    "dropout = config.dropout\n",
    "n_filters = config.n_filters\n",
    "filter_sizes = config.filter_sizes\n",
    "\n",
    "\n",
    "model = Model(vocab, tokenizer, n_filters, filter_sizes, dropout, output_dim, device)\n",
    "# copy pre-trained embeddings into model\n",
    "model.embedding.weight.data.copy_(vocab.vectors)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surprising-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "# first define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# function to calculate accuracy\n",
    "def accuracy(model_output, y_true):\n",
    "    y_pred = torch.argmax(model_output, dim=1)\n",
    "    return (y_pred == y_true).sum() / len(y_pred)\n",
    "\n",
    "def train(model, train_data, optimizer, loss_func):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_data, file=sys.stdout):\n",
    "        input_data, label = batch\n",
    "        label = torch.FloatTensor(label).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_data).squeeze(1)\n",
    "        \n",
    "        loss = loss_func(predictions, label.long())\n",
    "        acc = accuracy(predictions, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item(), 'train_acc': acc.item()})\n",
    "        \n",
    "    epoch_loss /= len(train_data)\n",
    "    epoch_acc /= len(train_data)\n",
    "    \n",
    "    wandb.log({'train_epoch_loss': epoch_loss, 'train_epoch_acc': epoch_acc})\n",
    "                \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, data, loss_func):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            input_data, label = batch\n",
    "            label = torch.FloatTensor(label).to(device)\n",
    "            predictions = model(input_data).squeeze(1)\n",
    "\n",
    "            loss += loss_func(predictions, label.long()).item()\n",
    "            acc += accuracy(predictions, label).item()\n",
    "            \n",
    "    loss /= len(data)\n",
    "    acc /= len(data)\n",
    "        \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-ambassador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 25.08it/s]\n",
      "train loss: 0.63 | train acc: 0.65\n",
      "val   loss: 0.57 | val   acc: 0.74\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.38it/s]\n",
      "train loss: 0.50 | train acc: 0.77\n",
      "val   loss: 0.51 | val   acc: 0.75\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.05it/s]\n",
      "train loss: 0.44 | train acc: 0.80\n",
      "val   loss: 0.50 | val   acc: 0.75\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.60it/s]\n",
      "train loss: 0.40 | train acc: 0.83\n",
      "val   loss: 0.46 | val   acc: 0.78\n",
      "100%|██████████| 40/40 [00:01<00:00, 37.10it/s]\n",
      "train loss: 0.36 | train acc: 0.85\n",
      "val   loss: 0.47 | val   acc: 0.78\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.61it/s]\n",
      "train loss: 0.33 | train acc: 0.86\n",
      "val   loss: 0.44 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.86it/s]\n",
      "train loss: 0.31 | train acc: 0.88\n",
      "val   loss: 0.44 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.79it/s]\n",
      "train loss: 0.29 | train acc: 0.88\n",
      "val   loss: 0.46 | val   acc: 0.78\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.22it/s]\n",
      "train loss: 0.26 | train acc: 0.90\n",
      "val   loss: 0.43 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.14it/s]\n",
      "train loss: 0.25 | train acc: 0.91\n",
      "val   loss: 0.45 | val   acc: 0.79\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.30it/s]\n",
      "train loss: 0.23 | train acc: 0.91\n",
      "val   loss: 0.43 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 34.98it/s]\n",
      "train loss: 0.21 | train acc: 0.92\n",
      "val   loss: 0.43 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.31it/s]\n",
      "train loss: 0.20 | train acc: 0.93\n",
      "val   loss: 0.44 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.59it/s]\n",
      "train loss: 0.19 | train acc: 0.93\n",
      "val   loss: 0.42 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 37.43it/s]\n",
      "train loss: 0.17 | train acc: 0.94\n",
      "val   loss: 0.46 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.46it/s]\n",
      "train loss: 0.16 | train acc: 0.95\n",
      "val   loss: 0.43 | val   acc: 0.81\n",
      "100%|██████████| 40/40 [00:01<00:00, 36.58it/s]\n",
      "train loss: 0.15 | train acc: 0.95\n",
      "val   loss: 0.46 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.65it/s]\n",
      "train loss: 0.14 | train acc: 0.96\n",
      "val   loss: 0.50 | val   acc: 0.79\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.00it/s]\n",
      "train loss: 0.13 | train acc: 0.96\n",
      "val   loss: 0.45 | val   acc: 0.80\n",
      "100%|██████████| 40/40 [00:01<00:00, 35.92it/s]\n",
      "train loss: 0.12 | train acc: 0.97\n",
      "val   loss: 0.46 | val   acc: 0.80\n",
      "Best validation loss: 0.42, accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# do the training\n",
    "best_val_loss = np.inf\n",
    "best_val_acc = np.inf\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_data_iterator, optimizer, loss_func)\n",
    "    val_epoch_loss, val_epoch_acc = evaluate(model, val_data_iterator, loss_func)\n",
    "    # log the validation results to wandb\n",
    "    wandb.log({'val_epoch_loss': val_epoch_loss, 'val_epoch_acc': val_epoch_acc})\n",
    "    print(f'train loss: {train_epoch_loss:.2f} | train acc: {train_epoch_acc:.2f}')\n",
    "    print(f'val   loss: {val_epoch_loss:.2f} | val   acc: {val_epoch_acc:.2f}')\n",
    "    # store model with best validation loss\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_val_acc = val_epoch_acc\n",
    "        # ensure we are in eval mode\n",
    "        model.eval()\n",
    "        torch.save(model, 'movie_review_model.pytorch')\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.2f}, accuracy: {best_val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confidential-twenty",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load best model from disk\n",
    "loaded_model = torch.load('movie_review_model.pytorch')\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# store as ONNX, needs example input\n",
    "x = next(iter(train_data_iterator))[0]\n",
    "torch.onnx.export(loaded_model, x, 'movie_review_model.onnx', opset_version=11,\n",
    "                  export_params=True, input_names=['input'], output_names=['output'],\n",
    "                  do_constant_folding=False,\n",
    "                  dynamic_axes={'input': {0: 'batch_size', 1: 'sentence_length'},\n",
    "                                'output': {0: 'batch_size'}})\n",
    "\n",
    "# check if we can load the onnx model\n",
    "import onnx\n",
    "mod = onnx.load('movie_review_model.onnx')\n",
    "onnx.checker.check_model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electronic-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polar-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to predict sentiment from a sentence\n",
    "class Predictor:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.classes = ['negative', 'positive']\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        # feed to model\n",
    "        pred = torch.softmax(model.forward([sentence]), dim=1)[0]\n",
    "        # get predicted class\n",
    "        idx = torch.argmax(pred)\n",
    "        return pred[idx].item(), self.classes[idx]\n",
    "    \n",
    "predict_sentiment = Predictor(loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dominican-masters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uneasy mishmash of styles and genres .\" - negative - 0.60\n",
      "\"this film 's relationship to actual tension is the same as what christmas-tree flocking in a spray can is to actual snow : a poor -- if durable -- imitation .\" - negative - 0.81\n",
      "\"by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\" - positive - 0.79\n",
      "\"director rob marshall went out gunning to make a great one .\" - positive - 0.81\n",
      "\"lathan and diggs have considerable personal charm , and their screen rapport makes the old story seem new .\" - positive - 0.99\n",
      "\"a well-made and often lovely depiction of the mysteries of friendship .\" - positive - 1.00\n",
      "\"none of this violates the letter of behan 's book , but missing is its spirit , its ribald , full-throated humor .\" - positive - 0.85\n",
      "\"although it bangs a very cliched drum at times , this crowd-pleaser 's fresh dialogue , energetic music , and good-natured spunk are often infectious .\" - positive - 0.98\n",
      "\"it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another .\" - negative - 0.52\n",
      "\"this is junk food cinema at its greasiest .\" - negative - 0.99\n"
     ]
    }
   ],
   "source": [
    "# print some predictions from the (unlabeled) test set\n",
    "sentences = pd.read_csv(os.path.join(data_path, 'test.tsv'), delimiter='\\t')['sentence']\n",
    "nmax = 10\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "for n, sentence in enumerate(sentences):\n",
    "    if n == nmax:\n",
    "        break\n",
    "    output_numerical, predicted_class = predict_sentiment(sentence)\n",
    "    print(f\"\\\"{sentence}\\\" - {predicted_class} - {output_numerical:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
