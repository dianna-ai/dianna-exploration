{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6627a4e-b920-42bb-9e23-660d9b4f51fe",
   "metadata": {},
   "source": [
    "## Movie review model generation\n",
    "This notebook handles the model generation for the movie review dataset.\n",
    "Before running this notebook, make sure to run the [data preparation notebook](./data_preparation.ipynb) to generate\n",
    "the word embeddings required for the model.  \n",
    "In addition to [PyTorch](https://pytorch.org/docs/stable/index.html), this notebook depends on [torchtext](https://pytorch.org/text/stable/index.html) for handling the input data. The notebook is also linked to [Weights & Biases](wandb.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9132ae5-d83d-4772-bd7c-19c40676fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b50ee-f535-4070-b103-e45f8138057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode = 'online'\n",
    "mode = 'disabled'\n",
    "wandb.init(project='movie-reviews', entity='dianna-ai', mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5863aba5-bbf2-4c69-9dd0-f6ac458d7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable hyperparameters\n",
    "config = wandb.config\n",
    "config.batch_size = 64\n",
    "config.epochs = 10\n",
    "config.output_dim = 1\n",
    "config.dropout = .4\n",
    "config.n_filters = 128\n",
    "config.filter_sizes = [3, 4, 5]\n",
    "config.learning_rate = 0.001\n",
    "config.weight_decay = 0.0003\n",
    "config.max_samples = 10000  # maximum samples of training set to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33274929-2fea-4e88-bfa8-f168f818b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch will use cuda\n"
     ]
    }
   ],
   "source": [
    "# select device to run on\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch will use {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98dcdcb-6a4a-4612-9e60-7e3d7d543ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data files\n",
    "data_path = os.path.join(os.path.expanduser('~'), 'surfdrive/Shared/datasets/stanford_sentiment_treebank_v2')\n",
    "\n",
    "# tokenizer for splitting input sentences\n",
    "tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "\n",
    "# word vectors as generated from data preparation notebook\n",
    "vocab = Vectors('word_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0cd22a-af88-4369-bbec-f35f89466498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to hold a dataset\n",
    "# custom datasets need to implement init, len, and getitem\n",
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, filename, tokenizer, vocab, max_samples=None, max_filter_size=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "        self.data = pd.read_csv(filename, delimiter='\\t')\n",
    "        if max_samples is not None:\n",
    "            self.data = self.data[:min(len(self.data), max_samples)]\n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "        # get sentence and corresponding label\n",
    "        sentence = self.data.iloc[idx]['sentence']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        # tokenize sentence\n",
    "        tokens = self.tokenizer(sentence)\n",
    "        # pad if needed\n",
    "        if self.max_filter_size is not None:\n",
    "            tokens = pad(tokens, self.max_filter_size)\n",
    "        # numericalize\n",
    "        tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>'] for token in tokens]\n",
    "        return tokens_numerical, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "# function to pad to some minimum length\n",
    "def pad(tokens, max_filter_size, padding_token='<pad>'):\n",
    "    npad = max(max_filter_size - len(tokens), 0)\n",
    "    tokens += [padding_token] * npad\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# custom collate function to handle variable-size input\n",
    "def collate(batch, padding_idx):\n",
    "    # get max sample size: item[0] is the input sentence split into numerical tokens\n",
    "    tokens = [sample[0] for sample in batch]\n",
    "    max_size = max(map(len, tokens))\n",
    "    # create input array with padding such that each element has the same size\n",
    "    input_data = np.empty((len(batch), max_size), dtype=int)\n",
    "    for i, item in enumerate(tokens):\n",
    "        # pad each element and store\n",
    "        input_data[i] = pad(item, max_size, padding_token=padding_idx)\n",
    "\n",
    "    # convert to tensors\n",
    "    input_data = torch.LongTensor(input_data)\n",
    "    labels = torch.FloatTensor([item[1] for item in batch])\n",
    "    return [input_data, labels]\n",
    "\n",
    "# convert collate function to callable that only requires batch as argument\n",
    "collate_func = lambda batch: collate(batch, vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56eb3164-66ac-4998-bd32-7605df8420b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into PyTorch dataset\n",
    "# These datasets return the input as numerical values, suited for input to the model\n",
    "\n",
    "train_data = MovieReviewDataset(os.path.join(data_path, 'train.tsv'), tokenizer, vocab, max_samples=config.max_samples)\n",
    "val_data = MovieReviewDataset(os.path.join(data_path, 'validation.tsv'), tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcef618-111c-4000-9274-683ae625fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators for the data\n",
    "batch_size = config.batch_size\n",
    "nworker = min(12, os.cpu_count() - 1)\n",
    "\n",
    "train_data_iterator = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func, num_workers=nworker, pin_memory=True)\n",
    "val_data_iterator = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func, num_workers=nworker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671ac01d-8a59-4e22-bdaa-2a9b350f7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, n_filters, filter_sizes, padding_idx,\n",
    "                dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for filter_size in filter_sizes:\n",
    "            layer = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_size, embedding_size))\n",
    "            self.conv_layers.append(layer)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # shape = [batch size, max nword per sentence]\n",
    "        embedding = self.embedding(text).unsqueeze(1)\n",
    "        # shape = [batch_size, 1, nword, embedding dim]\n",
    "        conved = [F.relu(conv(embedding)).squeeze(3) for conv in self.conv_layers]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter, nword - filter_size + 1]\n",
    "        # note: max_pool1d does not work with ONNX when output shape is dynamic\n",
    "        # therefore switched to adaptive_max_pool1d\n",
    "        pooled = [F.adaptive_max_pool1d(out, 1).squeeze(2) for out in conved]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter]\n",
    "        concat = torch.cat(pooled, dim=1)\n",
    "        # shape = [batch_size * len(filter_sizes), n_filter]\n",
    "        dropped = self.dropout(concat)\n",
    "        return self.fc(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2134661a-755e-4a91-b4c7-3f7e5558731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f65d2e4e7f0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init a model\n",
    "output_dim = config.output_dim\n",
    "dropout = config.dropout\n",
    "n_filters = config.n_filters\n",
    "filter_sizes = config.filter_sizes\n",
    "\n",
    "vocab_size, embedding_size = vocab.vectors.size()\n",
    "padding_idx = vocab.stoi['<pad>']\n",
    "\n",
    "model = Model(vocab_size, embedding_size, n_filters, filter_sizes, padding_idx, dropout, output_dim)\n",
    "# copy pre-trained embeddings into model\n",
    "model.embedding.weight.data.copy_(vocab.vectors)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c06cb93-d2f8-4a27-a33d-dd0f67477d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "# first define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "loss_func = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# function to calculate accuracy\n",
    "def accuracy(model_output, y_true):\n",
    "    y_pred = torch.round(torch.sigmoid(model_output))\n",
    "    return (y_pred == y_true).sum() / len(y_pred)\n",
    "\n",
    "def train(model, train_data, optimizer, loss_func):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_data):\n",
    "        input_data, label = batch\n",
    "        input_data = input_data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_data).squeeze(1)\n",
    "        \n",
    "        loss = loss_func(predictions, label)\n",
    "        acc = accuracy(predictions, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item(), 'train_acc': acc.item()})\n",
    "        \n",
    "    epoch_loss /= len(train_data)\n",
    "    epoch_acc /= len(train_data)\n",
    "    \n",
    "    wandb.log({'train_epoch_loss': epoch_loss, 'train_epoch_acc': epoch_acc})\n",
    "                \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, data, loss_func):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            input_data, label = batch\n",
    "            input_data = input_data.to(device)\n",
    "            label = label.to(device)\n",
    "            predictions = model(input_data).squeeze(1)\n",
    "\n",
    "            loss += loss_func(predictions, label).item()\n",
    "            acc += accuracy(predictions, label).item()\n",
    "            \n",
    "    loss /= len(data)\n",
    "    acc /= len(data)\n",
    "        \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4d5661-7fff-4b78-9ce5-40cbd9f5ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 128.28it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.50 | train acc: 0.75\n",
      "val   loss: 0.45 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 129.71it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.34 | train acc: 0.86\n",
      "val   loss: 0.43 | val   acc: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 132.03it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.26 | train acc: 0.90\n",
      "val   loss: 0.43 | val   acc: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 124.73it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.19 | train acc: 0.94\n",
      "val   loss: 0.43 | val   acc: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 129.29it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.15 | train acc: 0.95\n",
      "val   loss: 0.49 | val   acc: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 123.99it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.12 | train acc: 0.96\n",
      "val   loss: 0.48 | val   acc: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 127.26it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.10 | train acc: 0.97\n",
      "val   loss: 0.51 | val   acc: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 128.22it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09 | train acc: 0.98\n",
      "val   loss: 0.58 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 131.98it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.07 | train acc: 0.98\n",
      "val   loss: 0.61 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 128.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.07 | train acc: 0.98\n",
      "val   loss: 0.61 | val   acc: 0.79\n",
      "Best validation loss: 0.43, accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# do the training\n",
    "best_val_loss = np.inf\n",
    "best_val_acc = np.inf\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_data_iterator, optimizer, loss_func)\n",
    "    val_epoch_loss, val_epoch_acc = evaluate(model, val_data_iterator, loss_func)\n",
    "    # log the validation results to wandb\n",
    "    wandb.log({'val_epoch_loss': val_epoch_loss, 'val_epoch_acc': val_epoch_acc})\n",
    "    print(f'train loss: {train_epoch_loss:.2f} | train acc: {train_epoch_acc:.2f}')\n",
    "    print(f'val   loss: {val_epoch_loss:.2f} | val   acc: {val_epoch_acc:.2f}')\n",
    "    # store model with best validation loss\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_val_acc = val_epoch_acc\n",
    "        # ensure we are in eval mode\n",
    "        model.eval()\n",
    "        torch.save(model, 'movie_review_model.pytorch')\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.2f}, accuracy: {best_val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573e8c2d-da5d-45a2-96da-af7848dec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from disk\n",
    "loaded_model = torch.load('movie_review_model.pytorch')\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# store as ONNX, needs example input\n",
    "x = next(iter(train_data_iterator))[0].to(device)\n",
    "torch.onnx.export(loaded_model, x, 'movie_review_model.onnx', opset_version=11,\n",
    "                  export_params=True, input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size', 1: 'sentence_length'},\n",
    "                                'output': {0: 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d42394-4850-4042-a339-3c8f40b0c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to predict sentiment from a sentence\n",
    "class Predictor:\n",
    "    def __init__(self, model, tokenizer, vocab, device, max_filter_size=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "        self.max_filter_size = max_filter_size\n",
    "        self.classes = ['negative', 'positive']\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        # get numerical tokens\n",
    "        tokens = tokenizer(sentence)\n",
    "        # pad if needed\n",
    "        if self.max_filter_size is not None:\n",
    "            tokens = pad(tokens, self.max_filter_size)\n",
    "        # numericalize\n",
    "        tokens = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>'] for token in tokens]\n",
    "        # move to device and add required batch axis\n",
    "        tokens = torch.tensor(tokens).unsqueeze(0).to(self.device)\n",
    "        # feed to model\n",
    "        pred = torch.sigmoid(model.forward(tokens)).item()\n",
    "        # get string representation of predicted class\n",
    "        class_str = self.classes[int(np.round(pred))]\n",
    "        \n",
    "        return pred, class_str\n",
    "    \n",
    "predict_sentiment = Predictor(loaded_model, tokenizer, vocab, device, max_filter_size=max(config.filter_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cfb5b4-b0d4-46a1-87ed-ee0f346b0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uneasy mishmash of styles and genres .\" - negative - 0.28\n",
      "\"this film 's relationship to actual tension is the same as what christmas-tree flocking in a spray can is to actual snow : a poor -- if durable -- imitation .\" - negative - 0.00\n",
      "\"by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\" - positive - 0.78\n",
      "\"director rob marshall went out gunning to make a great one .\" - positive - 0.73\n",
      "\"lathan and diggs have considerable personal charm , and their screen rapport makes the old story seem new .\" - positive - 1.00\n",
      "\"a well-made and often lovely depiction of the mysteries of friendship .\" - positive - 1.00\n",
      "\"none of this violates the letter of behan 's book , but missing is its spirit , its ribald , full-throated humor .\" - positive - 0.98\n",
      "\"although it bangs a very cliched drum at times , this crowd-pleaser 's fresh dialogue , energetic music , and good-natured spunk are often infectious .\" - positive - 0.78\n",
      "\"it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another .\" - negative - 0.04\n",
      "\"this is junk food cinema at its greasiest .\" - negative - 0.00\n"
     ]
    }
   ],
   "source": [
    "# print some predictions from the (unlabeled) test set\n",
    "sentences = pd.read_csv(os.path.join(data_path, 'test.tsv'), delimiter='\\t')['sentence']\n",
    "nmax = 10\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "for n, sentence in enumerate(sentences):\n",
    "    if n == nmax:\n",
    "        break\n",
    "    output_numerical, predicted_class = predict_sentiment(sentence)\n",
    "    print(f\"\\\"{sentence}\\\" - {predicted_class} - {output_numerical:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
