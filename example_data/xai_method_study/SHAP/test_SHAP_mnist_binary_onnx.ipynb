{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SHAP using binary MNIST\n",
    "**Function        : Test SHAP using binary MNIST **<br>\n",
    "**Author          : Team DIANNA **<br>\n",
    "**Contributor     : **<br>\n",
    "**First Built     : 2021.06.23 **<br>\n",
    "**Last Update     : 2021.06.24 **<br>\n",
    "**Library         : os, numpy, matplotlib, torch, tensorflow, wandb **<br>\n",
    "**Description     : In this notebook we test XAI method SHAP using trained binary MNIST model.**<br>\n",
    "**Return Values   : Shapley scores**<br>\n",
    "**Note**          : We use Captum library to perform SHAP.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time as tt\n",
    "import numpy as np\n",
    "# DL framework\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.onnx\n",
    "# XAI framework\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import visualization as viz\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# report and monitoring with Weights & Biases\n",
    "#import wandb\n",
    "# ONNX model and runtime\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the dataset and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please specify data path\n",
    "datapath = '/mnt/d/NLeSC/DIANNA/data/mnist/binary-MNIST'\n",
    "# please specify model path\n",
    "model_path = '/mnt/d/NLeSC/DIANNA/codebase/dianna/example_data/model_generation/MNIST'\n",
    "# please specify output path\n",
    "output_path = '/mnt/d/NLeSC/DIANNA/codebase/dianna/example_data/xai_method_study'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (binary MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of mnist:\n",
      "dimensions or training set (12665, 784)\n",
      "dimensions or training set label (12665,)\n",
      "dimensions or testing set (2115, 784)\n",
      "dimensions or testing set label (2115,)\n",
      "statistics of training set:\n",
      "Digits: 0 1\n",
      "labels: [0 1]\n",
      "Class distribution: [5923 6742]\n",
      "Labels of training set [0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# load binary MNIST from local\n",
    "# load data\n",
    "fd = np.load(os.path.join(datapath, 'binary-mnist.npz'))\n",
    "# training set\n",
    "train_X = fd['X_train']\n",
    "train_y = fd['y_train']\n",
    "# testing set\n",
    "test_X = fd['X_test']\n",
    "test_y = fd['y_test']\n",
    "fd.close()\n",
    "\n",
    "# dimensions of data\n",
    "print(\"dimensions of mnist:\")\n",
    "print(\"dimensions or training set\", train_X.shape)\n",
    "print(\"dimensions or training set label\", train_y.shape)\n",
    "print(\"dimensions or testing set\", test_X.shape)\n",
    "print(\"dimensions or testing set label\", test_y.shape)\n",
    "# statistics of training set\n",
    "print(\"statistics of training set:\")\n",
    "print(\"Digits: 0 1\")\n",
    "print(\"labels: {}\".format(np.unique(train_y)))\n",
    "print(\"Class distribution: {}\".format(np.bincount(train_y)))\n",
    "print(\"Labels of training set\", train_y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch data loader\n",
    "test_X_torch = torch.from_numpy(test_X).type(torch.FloatTensor)\n",
    "test_y_torch = torch.from_numpy(test_y).type(torch.LongTensor)\n",
    "# reshape the input following the definition in pytorch (batch, channel, Height, Width)\n",
    "test_X_torch = test_X_torch.view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model (ONNX model trained for binary MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :\n",
      "\n",
      "graph torch-jit-export (\n",
      "  %input[FLOAT, batch_sizex1x28x28]\n",
      ") initializers (\n",
      "  %layer1.0.weight[FLOAT, 16x1x5x5]\n",
      "  %layer1.0.bias[FLOAT, 16]\n",
      "  %layer2.0.weight[FLOAT, 32x16x5x5]\n",
      "  %layer2.0.bias[FLOAT, 32]\n",
      "  %fc1.weight[FLOAT, 32x1568]\n",
      "  %fc1.bias[FLOAT, 32]\n",
      "  %fc2.weight[FLOAT, 10x32]\n",
      "  %fc2.bias[FLOAT, 10]\n",
      "  %26[INT64, 1]\n",
      ") {\n",
      "  %9 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%input, %layer1.0.weight, %layer1.0.bias)\n",
      "  %10 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%9)\n",
      "  %11 = Relu(%10)\n",
      "  %12 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%11, %layer2.0.weight, %layer2.0.bias)\n",
      "  %13 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%12)\n",
      "  %14 = Relu(%13)\n",
      "  %15 = Shape(%14)\n",
      "  %16 = Constant[value = <Scalar Tensor []>]()\n",
      "  %17 = Gather[axis = 0](%15, %16)\n",
      "  %19 = Unsqueeze[axes = [0]](%17)\n",
      "  %21 = Concat[axis = 0](%19, %26)\n",
      "  %22 = Reshape(%14, %21)\n",
      "  %23 = Gemm[alpha = 1, beta = 1, transB = 1](%22, %fc1.weight, %fc1.bias)\n",
      "  %24 = Gemm[alpha = 1, beta = 1, transB = 1](%23, %fc2.weight, %fc2.bias)\n",
      "  %output = LogSoftmax[axis = 1](%24)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# verify the ONNX model is valid\n",
    "onnx_file = os.path.join(model_path, 'mnist_model.onnx')\n",
    "onnx_model = onnx.load(onnx_file)\n",
    "# check that the IR is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "# print a human readable representation of the graph\n",
    "print('Model :\\n\\n{}'.format(onnx.helper.printable_graph(onnx_model.graph)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the class of the input image <br>\n",
    "About how to use ONNX model: https://pytorch.org/docs/stable/onnx.html <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [1]\n",
      "ground truth 1\n"
     ]
    }
   ],
   "source": [
    "# get ONNX predictions\n",
    "sess = ort.InferenceSession(onnx_file)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "onnx_input = {input_name: test_X_torch[:1,:,:,:].detach().numpy().astype(np.float32)}\n",
    "pred_onnx = sess.run([output_name], onnx_input)[0]\n",
    "predicted = np.argmax(pred_onnx,1)\n",
    "print(\"prediction\", predicted)\n",
    "print(\"ground truth\", test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-based attribution <br>\n",
    "Compute attributions using Integrated Gradients and visualize them on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captum lib cannot work on the onnx model\n",
    "#integrated_gradients = IntegratedGradients(onnx_model)\n",
    "#attributions_ig = integrated_gradients.attribute(test_X_torch[:1,:,:,:], target=test_y_torch[0], n_steps=100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e02b2587fbb2ca467fc85381f5522fddb4a9e5fbb8605712260c849ecf752b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}