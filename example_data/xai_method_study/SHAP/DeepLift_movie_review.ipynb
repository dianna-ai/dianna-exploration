{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of DeepLift with movie reviews\n",
    "\n",
    "**Function        : Exploration of DeepLift with movie reviews**<br>\n",
    "**Author          : Team DIANNA**<br>\n",
    "**Contributor     :**<br>\n",
    "**First Built     : 2021.10.26**<br>\n",
    "**Last Update     : 2021.10.26**<br>\n",
    "**Library         : os, numpy, matplotlib, torch, captum**<br>\n",
    "**Description     : In this notebook we test XAI method DeepLift using trained movie reviews model.**<br>\n",
    "**Return Values   : Sliency maps**<br>\n",
    "**Note**          : We use Captum library to perform DeepLift. This library works only with pytorch and it is not compitable with onnx.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from captum.attr import DeepLift\n",
    "import numpy as np\n",
    "# onnx module\n",
    "import onnxruntime as ort\n",
    "# text data processing\n",
    "import spacy\n",
    "from scipy.special import expit\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import Vectors\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please specify model path\n",
    "onnx_model_path = '/mnt/d/NLeSC/DIANNA/codebase/dianna/tests/test_data/movie_review_model.onnx'\n",
    "torch_model_path = '/mnt/d/NLeSC/DIANNA/codebase/dianna/tests/test_data/movie_review_model.pytorch'\n",
    "# word vector\n",
    "word_vector_file = '/mnt/d/NLeSC/DIANNA/codebase/dianna/tests/test_data/word_vectors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRunner():\n",
    "    def __init__(self, model_path, word_vector_file, max_filter_size):\n",
    "        self.filename = model_path\n",
    "        # ensure the spacy english is downloaded\n",
    "        spacy.cli.download('en_core_web_sm')\n",
    "        self.tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "        self.vocab = Vectors(word_vector_file, cache='.')\n",
    "\n",
    "        self.max_filter_size = max_filter_size\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        output = []\n",
    "\n",
    "        sess = ort.InferenceSession(self.filename)\n",
    "        input_name = sess.get_inputs()[0].name\n",
    "        output_name = sess.get_outputs()[0].name\n",
    "\n",
    "        for sentence in self.normalize_sentences(sentences):\n",
    "            # feed to model\n",
    "            onnx_input = {input_name: [sentence]}\n",
    "            pred = expit(sess.run([output_name], onnx_input)[0])\n",
    "\n",
    "            # output 2 classes\n",
    "            positivity = pred[:, 0]\n",
    "            negativity = 1 - positivity\n",
    "\n",
    "            output.append(np.transpose([negativity, positivity])[0])\n",
    "\n",
    "        return np.array(output)\n",
    "\n",
    "    def normalize_sentences(self, sentences):\n",
    "        \"\"\"\n",
    "        Convert input to desired format.\n",
    "        \"\"\"\n",
    "        if isinstance(sentences, str):\n",
    "            return [self.numericalizer(sentences)]\n",
    "        elif isinstance(sentences, list):\n",
    "            if isinstance(sentences[0], str):\n",
    "                return [self.numericalizer(sentence) for sentence in sentences]\n",
    "            elif torch.is_tensor(sentences[0]):\n",
    "                return sentences\n",
    "    \n",
    "    def numericalizer(self, sentence):\n",
    "        \"\"\"\n",
    "        From sentence to tensor.\n",
    "        \"\"\"\n",
    "        # get tokens\n",
    "        tokens = self.tokenizer(sentence)\n",
    "        if len(tokens) < self.max_filter_size:\n",
    "            tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "\n",
    "        # numericalize\n",
    "        tokens = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>'] for token in\n",
    "                  tokens]\n",
    "\n",
    "        # add required batch axis\n",
    "        tokens = torch.tensor(tokens).unsqueeze(0)\n",
    "\n",
    "        return torch.as_tensor(tokens)#.requires_grad_()#.type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "runner = ModelRunner(onnx_model_path, word_vector_file, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, n_filters, filter_sizes, padding_idx,\n",
    "                dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for filter_size in filter_sizes:\n",
    "            layer = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_size, embedding_size))\n",
    "            self.conv_layers.append(layer)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # shape = [batch size, max nword per sentence]\n",
    "        embedding = self.embedding(text).unsqueeze(1)\n",
    "        # shape = [batch_size, 1, nword, embedding dim]\n",
    "        conved = [F.relu(conv(embedding)).squeeze(3) for conv in self.conv_layers]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter, nword - filter_size + 1]\n",
    "        # note: max_pool1d does not work with ONNX when output shape is dynamic\n",
    "        # therefore switched to adaptive_max_pool1d\n",
    "        pooled = [F.adaptive_max_pool1d(out, 1).squeeze(2) for out in conved]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter]\n",
    "        concat = torch.cat(pooled, dim=1)\n",
    "        # shape = [batch_size * len(filter_sizes), n_filter]\n",
    "        dropped = self.dropout(concat)\n",
    "        return self.fc(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(13889, 100, padding_idx=1)\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv2d(1, 245, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 245, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 245, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.6913344449168243, inplace=False)\n",
       "  (fc): Linear(in_features=735, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model from disk\n",
    "model = torch.load(torch_model_path, map_location=torch.device('cpu'))\n",
    "#model = loaded_model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangliu/miniconda3/lib/python3.8/site-packages/captum/_utils/gradient.py:49: UserWarning: Input Tensor 0 has a dtype of torch.int64.\n",
      "                    Gradients cannot be activated\n",
      "                    for these data types.\n",
      "  warnings.warn(\n",
      "/home/yangliu/miniconda3/lib/python3.8/site-packages/captum/attr/_core/deep_lift.py:322: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors does not require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-efd21052289f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#deeplift = DeepLift(runner)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdeeplift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattributions_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeeplift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta, custom_attribution_func)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_forward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcustom_attribution_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiplies_by_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# contains batch_size * #steps elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
     ]
    }
   ],
   "source": [
    "review = 'such a bad movie'\n",
    "#deeplift = DeepLift(runner)\n",
    "deeplift = DeepLift(model)\n",
    "attributions_dl = deeplift.attribute(runner.numericalizer(review))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
