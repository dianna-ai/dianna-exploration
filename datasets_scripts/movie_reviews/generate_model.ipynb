{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6627a4e-b920-42bb-9e23-660d9b4f51fe",
   "metadata": {},
   "source": [
    "## Movie review data preparation\n",
    "This notebook handles the data preparation for a neural network to predict the sentiment of movie reviews.\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html) is used for handling the input data\n",
    "\n",
    "Additional dependencies:  \n",
    "[spacy](https://spacy.io) for tokenizing (used by torchtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9132ae5-d83d-4772-bd7c-19c40676fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from torchtext.legacy.data import Field\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b50ee-f535-4070-b103-e45f8138057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mloostrum\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">genial-blaze-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dianna-ai/movie-reviews\" target=\"_blank\">https://wandb.ai/dianna-ai/movie-reviews</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dianna-ai/movie-reviews/runs/2kqmaqq5\" target=\"_blank\">https://wandb.ai/dianna-ai/movie-reviews/runs/2kqmaqq5</a><br/>\n",
       "                Run data is saved locally in <code>/home/leon/nlesc/DIANNA/dianna/datasets_scripts/movie_reviews/wandb/run-20210601_110136-2kqmaqq5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2kqmaqq5)</h1><iframe src=\"https://wandb.ai/dianna-ai/movie-reviews/runs/2kqmaqq5\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f150d1dd520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='movie-reviews', entity='dianna-ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5863aba5-bbf2-4c69-9dd0-f6ac458d7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.batch_size = 64\n",
    "config.epochs = 10\n",
    "config.output_dim = 1\n",
    "config.dropout = .2\n",
    "config.n_filters = 128\n",
    "config.filter_sizes = [3, 4, 5]\n",
    "config.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dfdeb3-03a1-434d-8841-36dd72bb4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spacy and download word embeddings\n",
    "# !pip install spacy\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0cd22a-af88-4369-bbec-f35f89466498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to hold a dataset\n",
    "# custom datasets need to implement init, len, and getitem\n",
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, filename, tokenizer, vocab, max_samples=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.data = pd.read_csv(filename, delimiter='\\t')\n",
    "        if max_samples is not None:\n",
    "            self.data = self.data[:min(len(self.data), max_samples)]\n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "        # tokenize sentence\n",
    "        tokens = self.tokenizer(self.data.iloc[idx]['sentence'])\n",
    "        # numericalize\n",
    "        tokens_numerical = [self.vocab.stoi[token] for token in tokens]\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return tokens_numerical, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "# custom collate function to handle variable-size input\n",
    "def collate(batch, padding_token_numerical):\n",
    "    # get max sample size: item[0] is the input sentence split into numerical tokens\n",
    "    tokens = [sample[0] for sample in batch]\n",
    "    max_size = max(map(len, tokens))\n",
    "    # create input array with padding such that each element has the same size\n",
    "    input_data = []\n",
    "    for item in tokens:\n",
    "        # required padding\n",
    "        npad = max_size - len(item)\n",
    "        input_data.append(item + [padding_token_numerical] * npad)\n",
    "    \n",
    "    # convert to tensors\n",
    "    input_data = torch.LongTensor(input_data)\n",
    "    labels = torch.FloatTensor([item[1] for item in batch])\n",
    "    return [input_data, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6153f31d-5da5-4dfe-bcec-de74b2f9d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 13889\n",
      "Embedding size: 100\n",
      "Padding token index: 1\n",
      "Unknown token index: 0\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary from training data\n",
    "data_path = os.path.join(os.path.expanduser('~'), 'surfdrive/Shared/datasets/stanford_sentiment_treebank_v2')\n",
    "\n",
    "# tokenizer for splitting input sentences\n",
    "tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "\n",
    "# load raw training data\n",
    "raw_train_data = pd.read_csv(os.path.join(data_path, 'train.tsv'), delimiter='\\t')\n",
    "\n",
    "# TODO: why does this split input on individual letters instead of words?\n",
    "# TEXT = Field(sequential=True, tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "# TEXT.build_vocab(raw_train_data['sentence'], vectors='glove.6B.100d')\n",
    "\n",
    "# split input into tokens\n",
    "train_tokens = [tokenizer(sentence) for sentence in raw_train_data['sentence']]\n",
    "\n",
    "# Create field and build vocabulary\n",
    "text_field = Field()\n",
    "text_field.build_vocab(train_tokens, vectors='glove.6B.100d')\n",
    "vocab_size = len(text_field.vocab.freqs) + 2  # add the padding and unknown token\n",
    "embedding_size = text_field.vocab.vectors.shape[1]\n",
    "padding_idx = text_field.vocab.stoi[text_field.pad_token]\n",
    "unknown_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "\n",
    "# define collate function with now known padding token\n",
    "collate_func = lambda batch: collate(batch, padding_idx)\n",
    "\n",
    "print(f'Vocab size: {vocab_size}')\n",
    "print(f'Embedding size: {embedding_size}')\n",
    "print(f'Padding token index: {padding_idx}')\n",
    "print(f'Unknown token index: {unknown_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56eb3164-66ac-4998-bd32-7605df8420b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into PyTorch dataset\n",
    "# These datasets return the input as numerical values, suited for input to the model\n",
    "max_samples = 10000\n",
    "\n",
    "train_data = MovieReviewDataset(os.path.join(data_path, 'train.tsv'), tokenizer, text_field.vocab, max_samples=max_samples)\n",
    "val_data = MovieReviewDataset(os.path.join(data_path, 'validation.tsv'), tokenizer, text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcef618-111c-4000-9274-683ae625fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 42])\n",
      "torch.Size([64])\n",
      "tensor([[    4,   412,     3,  ...,     4,  5886,     7],\n",
      "        [   11,  3640,  1309,  ...,     1,     1,     1],\n",
      "        [    2,  4199,  4053,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [10246,     6,   142,  ...,     1,     1,     1],\n",
      "        [  119,    31,     1,  ...,     1,     1,     1],\n",
      "        [ 6939,     1,     1,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "# Create iterators for the data\n",
    "batch_size = config.batch_size\n",
    "\n",
    "train_data_iterator = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "val_data_iterator = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "\n",
    "# test\n",
    "features, labels = next(iter(train_data_iterator))\n",
    "print(features.size())\n",
    "print(labels.size())\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a656c2-ac47-4244-99f1-33dcbe522f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device to run on\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "# print(f'PyTorch will use {device}')\n",
    "\n",
    "# crashes on GPU after ~1.5 epoch, only run on cpu for now\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "671ac01d-8a59-4e22-bdaa-2a9b350f7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, n_filters, filter_sizes, padding_idx,\n",
    "                dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for filter_size in filter_sizes:\n",
    "            layer = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_size, embedding_size))\n",
    "            self.conv_layers.append(layer)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # shape = [batch size, max nword per sentence]\n",
    "        embedding = self.embedding(text).unsqueeze(1)\n",
    "        # shape = [batch_size, 1, nword, embedding dim]\n",
    "        conved = [F.relu(conv(embedding)).squeeze(3) for conv in self.conv_layers]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter, nword - filter_size + 1]\n",
    "        pooled = [F.max_pool1d(out, out.shape[2]).squeeze(2) for out in conved]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter]\n",
    "        concat = torch.cat(pooled, dim=1)\n",
    "        # shape = [batch_size * len(filter_sizes), n_filter]\n",
    "        dropped = self.dropout(concat)\n",
    "        return torch.sigmoid(self.fc(dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2134661a-755e-4a91-b4c7-3f7e5558731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f14f1facc40>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init a model\n",
    "output_dim = config.output_dim\n",
    "dropout = config.dropout\n",
    "n_filters = config.n_filters\n",
    "filter_sizes = config.filter_sizes\n",
    "\n",
    "model = Model(vocab_size, embedding_size, n_filters, filter_sizes, padding_idx, dropout, output_dim)\n",
    "# copy pre-trained embeddings into model\n",
    "model.embedding.weight.data.copy_(text_field.vocab.vectors)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c06cb93-d2f8-4a27-a33d-dd0f67477d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "# first define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "loss_func = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# function to calculate accuracy\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.round(y_pred)\n",
    "    return (y_pred == y_true).sum() / len(y_pred)\n",
    "\n",
    "def train(model, train_data, optimizer, loss_func, val_data=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_data):\n",
    "        input_data, label = batch\n",
    "        input_data = input_data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_data).squeeze(1)\n",
    "        \n",
    "        loss = loss_func(predictions, label)\n",
    "        acc = accuracy(predictions, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item(), 'train_acc': acc.item()})\n",
    "        \n",
    "    epoch_loss /= len(train_data)\n",
    "    epoch_acc /= len(train_data)\n",
    "    \n",
    "    wandb.log({'epoch_loss': epoch_loss, 'epoch_acc': epoch_acc})\n",
    "        \n",
    "    # validation\n",
    "    if val_data is not None:\n",
    "        with torch.no_grad():\n",
    "            for batch in val_data:\n",
    "                input_data, label = batch\n",
    "                input_data = input_data.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                predictions = model(input_data).squeeze(1)\n",
    "                \n",
    "                val_loss += loss_func(predictions, label).item()\n",
    "                val_acc += accuracy(predictions, label).item()\n",
    "                \n",
    "            val_loss /= len(val_data)\n",
    "            val_acc /= len(val_data)\n",
    "            \n",
    "        wandb.log({'val_epoch_loss': val_loss, 'val_epoch_acc': val_acc})\n",
    "                \n",
    "    return epoch_loss, epoch_acc, val_loss, val_acc\n",
    "\n",
    "def evaluate(model, data, loss_func):\n",
    "    \n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            input_data, label = batch\n",
    "            input_data = input_data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            predictions = model(input_data).squeeze(1)\n",
    "            \n",
    "            loss += loss_func(predictions, label).item()\n",
    "            acc += accuracy(predictions, label).item()\n",
    "            \n",
    "    loss /= len(data)\n",
    "    acc /= len(data)\n",
    "        \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4d5661-7fff-4b78-9ce5-40cbd9f5ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:07<00:00, 20.23it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.57it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.96it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.71it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.57it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.85it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.12it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.26it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.19it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# do the training\n",
    "epochs = config.epochs\n",
    "loss = np.zeros(epochs)\n",
    "acc = np.zeros(epochs)\n",
    "val_loss = np.zeros(epochs)\n",
    "val_acc = np.zeros(epochs)\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = train(model, train_data_iterator, optimizer, loss_func, val_data=val_data_iterator)\n",
    "    loss[epoch] = epoch_loss\n",
    "    acc[epoch] = epoch_acc\n",
    "    val_loss[epoch] = epoch_val_loss\n",
    "    val_acc[epoch] = epoch_val_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab048ff-6567-4bdc-beef-e12c1cca1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the model\n",
    "model.eval()\n",
    "torch.save(model, 'movie_review_model.pytorch')\n",
    "\n",
    "# store as ONNX, needs example input\n",
    "# x = next(iter(train_data_iterator))[0]\n",
    "# torch.onnx.export(model, x, 'move_review_model.onnx', opset_version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f9987-e820-49e3-a33c-d07c280b35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(acc, label='acc')\n",
    "plt.plot(val_acc, label='val acc')\n",
    "plt.title('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f736254-b6a5-413a-a6d3-ff9a8b192de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from disk\n",
    "# loaded_model = Model(vocab_size, embedding_size, n_filters, filter_sizes, padding_idx, dropout, output_dim)\n",
    "# loaded_model.load_state_dict(torch.load('movie_review_model.pytorch'))\n",
    "loaded_model = torch.load('movie_review_model.pytorch')\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    # depends on loaded_model, tokenizer, text_field\n",
    "    # convert sentence into tokens\n",
    "    tokens = tokenizer(sentence)\n",
    "    # must be at least the size of the largest filter\n",
    "    if len(tokens) < max(filter_sizes):\n",
    "        tokens += [text_field.pad_token] * (max(filter_size) - len(tokens))\n",
    "    # convert to numerical and transfer to device\n",
    "    tokens = [text_field.vocab.stoi[word] for word in tokens]\n",
    "    tokens = torch.tensor(tokens).to(device)\n",
    "    # add batch axis\n",
    "    tensor = tokens.unsqueeze(0)\n",
    "    prediction = loaded_model(tensor)\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfb5b4-b0d4-46a1-87ed-ee0f346b0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some predictions from the (unlabeled) test set\n",
    "sentences = pd.read_csv(os.path.join(data_path, 'test.tsv'), delimiter='\\t')['sentence']\n",
    "nmax = 10\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "for n, sentence in enumerate(sentences):\n",
    "    if n == nmax:\n",
    "        break\n",
    "    output = predict_sentiment(sentence)\n",
    "    predicted_class = classes[int(np.round(output))]\n",
    "    print(f\"\\\"{sentence}\\\" - {predicted_class} - {output:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
