{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6627a4e-b920-42bb-9e23-660d9b4f51fe",
   "metadata": {},
   "source": [
    "## Movie review data preparation\n",
    "This notebook handles the data preparation for a neural network to predict the sentiment of movie reviews.\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html) is used for handling the input data\n",
    "\n",
    "Additional dependencies:  \n",
    "[spacy](https://spacy.io) for tokenizing (used by torchtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9132ae5-d83d-4772-bd7c-19c40676fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from torchtext.legacy.data import Field\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b50ee-f535-4070-b103-e45f8138057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode = 'online'\n",
    "mode = 'disabled'\n",
    "wandb.init(project='movie-reviews', entity='dianna-ai', mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5863aba5-bbf2-4c69-9dd0-f6ac458d7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.batch_size = 64\n",
    "config.epochs = 10\n",
    "config.output_dim = 1\n",
    "config.dropout = .4\n",
    "config.n_filters = 128\n",
    "config.filter_sizes = [3, 4, 5]\n",
    "config.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dfdeb3-03a1-434d-8841-36dd72bb4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spacy and download word embeddings\n",
    "# !pip install spacy\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0cd22a-af88-4369-bbec-f35f89466498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to hold a dataset\n",
    "# custom datasets need to implement init, len, and getitem\n",
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, filename, tokenizer, vocab, max_samples=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.data = pd.read_csv(filename, delimiter='\\t')\n",
    "        if max_samples is not None:\n",
    "            self.data = self.data[:min(len(self.data), max_samples)]\n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "        # tokenize sentence\n",
    "        tokens = self.tokenizer(self.data.iloc[idx]['sentence'])\n",
    "        # numericalize\n",
    "        tokens_numerical = [self.vocab.stoi[token] for token in tokens]\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return tokens_numerical, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "# custom collate function to handle variable-size input\n",
    "def collate(batch, padding_token_numerical):\n",
    "    # get max sample size: item[0] is the input sentence split into numerical tokens\n",
    "    tokens = [sample[0] for sample in batch]\n",
    "    max_size = max(map(len, tokens))\n",
    "    # create input array with padding such that each element has the same size\n",
    "    input_data = []\n",
    "    for item in tokens:\n",
    "        # required padding\n",
    "        npad = max_size - len(item)\n",
    "        input_data.append(item + [padding_token_numerical] * npad)\n",
    "    \n",
    "    # convert to tensors\n",
    "    input_data = torch.LongTensor(input_data)\n",
    "    labels = torch.FloatTensor([item[1] for item in batch])\n",
    "    return [input_data, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6153f31d-5da5-4dfe-bcec-de74b2f9d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 13889\n",
      "Embedding size: 100\n",
      "Padding token index: 1\n",
      "Unknown token index: 0\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary from training data\n",
    "data_path = os.path.join(os.path.expanduser('~'), 'surfdrive/Shared/datasets/stanford_sentiment_treebank_v2')\n",
    "\n",
    "# tokenizer for splitting input sentences\n",
    "tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "\n",
    "# load raw training data\n",
    "raw_train_data = pd.read_csv(os.path.join(data_path, 'train.tsv'), delimiter='\\t')\n",
    "\n",
    "# split input into tokens\n",
    "train_tokens = [tokenizer(sentence) for sentence in raw_train_data['sentence']]\n",
    "\n",
    "# Create field and build vocabulary\n",
    "text_field = Field()\n",
    "text_field.build_vocab(train_tokens, vectors='glove.6B.100d')\n",
    "vocab_size = len(text_field.vocab.freqs) + 2  # add the padding and unknown token\n",
    "embedding_size = text_field.vocab.vectors.shape[1]\n",
    "padding_idx = text_field.vocab.stoi[text_field.pad_token]\n",
    "unknown_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "\n",
    "# define collate function with now known padding token\n",
    "collate_func = lambda batch: collate(batch, padding_idx)\n",
    "\n",
    "print(f'Vocab size: {vocab_size}')\n",
    "print(f'Embedding size: {embedding_size}')\n",
    "print(f'Padding token index: {padding_idx}')\n",
    "print(f'Unknown token index: {unknown_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56eb3164-66ac-4998-bd32-7605df8420b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into PyTorch dataset\n",
    "# These datasets return the input as numerical values, suited for input to the model\n",
    "max_samples = 10000\n",
    "\n",
    "train_data = MovieReviewDataset(os.path.join(data_path, 'train.tsv'), tokenizer, text_field.vocab, max_samples=max_samples)\n",
    "val_data = MovieReviewDataset(os.path.join(data_path, 'validation.tsv'), tokenizer, text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcef618-111c-4000-9274-683ae625fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators for the data\n",
    "batch_size = config.batch_size\n",
    "\n",
    "train_data_iterator = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "val_data_iterator = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a656c2-ac47-4244-99f1-33dcbe522f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch will use cuda\n"
     ]
    }
   ],
   "source": [
    "# select device to run on\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'PyTorch will use {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671ac01d-8a59-4e22-bdaa-2a9b350f7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, n_filters, filter_sizes, padding_idx,\n",
    "                dropout, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for filter_size in filter_sizes:\n",
    "            layer = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_size, embedding_size))\n",
    "            self.conv_layers.append(layer)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # shape = [batch size, max nword per sentence]\n",
    "        embedding = self.embedding(text).unsqueeze(1)\n",
    "        # shape = [batch_size, 1, nword, embedding dim]\n",
    "        conved = [F.relu(conv(embedding)).squeeze(3) for conv in self.conv_layers]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter, nword - filter_size + 1]\n",
    "        # note: max_pool1d does not work with ONNX when output shape is dynamic\n",
    "        # therefore switched to adaptive_max_pool1d\n",
    "        pooled = [F.adaptive_max_pool1d(out, 1).squeeze(2) for out in conved]\n",
    "        # shape = len(filter_sizes) list of [batch_size, n_filter]\n",
    "        concat = torch.cat(pooled, dim=1)\n",
    "        # shape = [batch_size * len(filter_sizes), n_filter]\n",
    "        dropped = self.dropout(concat)\n",
    "        return self.fc(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2134661a-755e-4a91-b4c7-3f7e5558731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f5cf3faf640>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init a model\n",
    "output_dim = config.output_dim\n",
    "dropout = config.dropout\n",
    "n_filters = config.n_filters\n",
    "filter_sizes = config.filter_sizes\n",
    "\n",
    "model = Model(vocab_size, embedding_size, n_filters, filter_sizes, padding_idx, dropout, output_dim)\n",
    "# copy pre-trained embeddings into model\n",
    "model.embedding.weight.data.copy_(text_field.vocab.vectors)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c06cb93-d2f8-4a27-a33d-dd0f67477d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluation functions\n",
    "# first define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "loss_func = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# function to calculate accuracy\n",
    "def accuracy(model_output, y_true):\n",
    "    y_pred = torch.round(torch.sigmoid(model_output))\n",
    "    return (y_pred == y_true).sum() / len(y_pred)\n",
    "\n",
    "def train(model, train_data, optimizer, loss_func):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_data):\n",
    "        input_data, label = batch\n",
    "        input_data = input_data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(input_data).squeeze(1)\n",
    "        \n",
    "        loss = loss_func(predictions, label)\n",
    "        acc = accuracy(predictions, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item(), 'train_acc': acc.item()})\n",
    "        \n",
    "    epoch_loss /= len(train_data)\n",
    "    epoch_acc /= len(train_data)\n",
    "    \n",
    "    wandb.log({'train_epoch_loss': epoch_loss, 'train_epoch_acc': epoch_acc})\n",
    "                \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, data, loss_func):\n",
    "    \n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data:\n",
    "            input_data, label = batch\n",
    "            input_data = input_data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            predictions = model(input_data).squeeze(1)\n",
    "            \n",
    "            loss += loss_func(predictions, label).item()\n",
    "            acc += accuracy(predictions, label).item()\n",
    "            \n",
    "    loss /= len(data)\n",
    "    acc /= len(data)\n",
    "        \n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4d5661-7fff-4b78-9ce5-40cbd9f5ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.51it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.49 | train acc: 0.76\n",
      "val   loss: 0.44 | val   acc: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.83it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.30 | train acc: 0.88\n",
      "val   loss: 0.52 | val   acc: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.75it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 41.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.20 | train acc: 0.92\n",
      "val   loss: 0.47 | val   acc: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.70it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13 | train acc: 0.95\n",
      "val   loss: 0.53 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.72it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09 | train acc: 0.97\n",
      "val   loss: 0.55 | val   acc: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.71it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.06 | train acc: 0.98\n",
      "val   loss: 0.66 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.68it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.05 | train acc: 0.99\n",
      "val   loss: 0.66 | val   acc: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.68it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 40.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.04 | train acc: 0.99\n",
      "val   loss: 0.80 | val   acc: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.65it/s]\n",
      "  3%|▎         | 5/157 [00:00<00:03, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.03 | train acc: 0.99\n",
      "val   loss: 0.80 | val   acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.03 | train acc: 0.99\n",
      "val   loss: 0.96 | val   acc: 0.76\n",
      "Best validation loss: 0.44, accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# do the training\n",
    "best_val_loss = np.inf\n",
    "best_val_acc = np.inf\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_data_iterator, optimizer, loss_func)\n",
    "    val_epoch_loss, val_epoch_acc = evaluate(model, val_data_iterator, loss_func)\n",
    "    # log the validation results to wandb\n",
    "    wandb.log({'val_epoch_loss': val_epoch_loss, 'val_epoch_acc': val_epoch_acc})\n",
    "    print(f'train loss: {train_epoch_loss:.2f} | train acc: {train_epoch_acc:.2f}')\n",
    "    print(f'val   loss: {val_epoch_loss:.2f} | val   acc: {val_epoch_acc:.2f}')\n",
    "    # store model with best validation loss\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_val_acc = val_epoch_acc\n",
    "        # ensure we are in eval mode\n",
    "        model.eval()\n",
    "        torch.save(model, 'movie_review_model.pytorch')\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.2f}, accuracy: {best_val_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573e8c2d-da5d-45a2-96da-af7848dec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from disk\n",
    "loaded_model = torch.load('movie_review_model.pytorch')\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# store as ONNX, needs example input\n",
    "x = next(iter(train_data_iterator))[0].to(device)\n",
    "torch.onnx.export(model, x, 'movie_review_model.onnx', opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d42394-4850-4042-a339-3c8f40b0c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict sentiment from a sentence\n",
    "def predict_sentiment(sentence):\n",
    "    # depends on loaded_model, tokenizer, text_field\n",
    "    # convert sentence into tokens\n",
    "    tokens = tokenizer(sentence)\n",
    "    # must be at least the size of the largest filter\n",
    "    if len(tokens) < max(filter_sizes):\n",
    "        tokens += [text_field.pad_token] * (max(filter_size) - len(tokens))\n",
    "    # convert to numerical and transfer to device\n",
    "    tokens = [text_field.vocab.stoi[word] for word in tokens]\n",
    "    tokens = torch.tensor(tokens).to(device)\n",
    "    # add batch axis\n",
    "    tensor = tokens.unsqueeze(0)\n",
    "    prediction = loaded_model(tensor)\n",
    "    return torch.sigmoid(prediction).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cfb5b4-b0d4-46a1-87ed-ee0f346b0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"uneasy mishmash of styles and genres .\" - positive - 0.68\n",
      "\"this film 's relationship to actual tension is the same as what christmas-tree flocking in a spray can is to actual snow : a poor -- if durable -- imitation .\" - negative - 0.34\n",
      "\"by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\" - positive - 0.66\n",
      "\"director rob marshall went out gunning to make a great one .\" - positive - 0.54\n",
      "\"lathan and diggs have considerable personal charm , and their screen rapport makes the old story seem new .\" - positive - 0.94\n",
      "\"a well-made and often lovely depiction of the mysteries of friendship .\" - positive - 0.99\n",
      "\"none of this violates the letter of behan 's book , but missing is its spirit , its ribald , full-throated humor .\" - positive - 0.90\n",
      "\"although it bangs a very cliched drum at times , this crowd-pleaser 's fresh dialogue , energetic music , and good-natured spunk are often infectious .\" - positive - 0.88\n",
      "\"it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another .\" - negative - 0.40\n",
      "\"this is junk food cinema at its greasiest .\" - negative - 0.16\n"
     ]
    }
   ],
   "source": [
    "# print some predictions from the (unlabeled) test set\n",
    "sentences = pd.read_csv(os.path.join(data_path, 'test.tsv'), delimiter='\\t')['sentence']\n",
    "nmax = 10\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "for n, sentence in enumerate(sentences):\n",
    "    if n == nmax:\n",
    "        break\n",
    "    output = predict_sentiment(sentence)\n",
    "    predicted_class = classes[int(np.round(output))]\n",
    "    print(f\"\\\"{sentence}\\\" - {predicted_class} - {output:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ecf31-eadc-4927-8a20-dec7136d4ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
