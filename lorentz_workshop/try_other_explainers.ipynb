{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf\n",
    "import numpy as np\n",
    "import dianna\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import onnxruntime\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import random\n",
    "import torch\n",
    "from scipy.stats import wasserstein_distance, kendalltau, pearsonr\n",
    "from functools import partial\n",
    "from torch.nn.functional import mse_loss\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data, name):\n",
    "    fname           = str(Path('models', name))\n",
    "    sess            = onnxruntime.InferenceSession(fname)\n",
    "    input_name      = sess.get_inputs()[0].name\n",
    "    output_name     = sess.get_outputs()[0].name\n",
    "\n",
    "    onnx_input      = {input_name: data}\n",
    "    pred_onnx       = sess.run([output_name], onnx_input)\n",
    "\n",
    "    return softmax(pred_onnx[0], axis=1)\n",
    "\n",
    "def prepare_data(data_path):\n",
    "    data = dict(np.load(data_path))\n",
    "    if 'color' in data_path.split('/')[-1]:\n",
    "        data['images']          = np.array(data['images'], dtype='float32') / 255.\n",
    "    elif 'rotation' in data_path.split('/')[-1]:\n",
    "        data['images']          = np.array(data['images'], dtype='float32') / 255.\n",
    "    elif 'roundedness' in data_path.split('/')[-1]:\n",
    "        data['images']          = np.array(data['images'], dtype='float32')\n",
    "    data['images']          = data['images'][:100]\n",
    "    data['labels']          = np.array(data['labels'], dtype=int)\n",
    "    data['labels']          = data['labels'][:100]\n",
    "    data['images'] = data['images'].reshape(-1, 1, 64, 64)\n",
    "    return data\n",
    "\n",
    "def pca(x):\n",
    "    X_train                 = np.array(x)\n",
    "    sc                      = StandardScaler()\n",
    "    X_train_std             = sc.fit_transform(X_train)\n",
    "    cov_mat                 = np.cov(X_train_std.T)\n",
    "    eigen_vals, eigen_vecs  = np.linalg.eig(cov_mat)\n",
    "\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]\n",
    "\n",
    "    # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "    eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "    w = np.hstack((eigen_pairs[0][1][:, np.newaxis], eigen_pairs[1][1][:, np.newaxis]))\n",
    "    X_train_std[0].dot(w)\n",
    "\n",
    "    X_train_pca = X_train_std.dot(w)\n",
    "\n",
    "    return X_train_pca\n",
    "\n",
    "def minmax(values):\n",
    "    return (values -values.min()) / ((values.max() - values.min())+10e-12)\n",
    "\n",
    "# fill each pixel with SHAP values \n",
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change this variable according to the path to the repository\n",
    "repo_path = \"/home/your_username/dianna-exploration\"\n",
    "\n",
    "for model_name in [\"pytorch\", \"original\"]:\n",
    "    for explainer in [\"rise\", \"lime\"]: # shap\n",
    "        for task_name in [\"color\", \"rotation\", \"roundedness\"]:\n",
    "            OUT_PATH = f\"{repo_path}/lorentz_workshop/explainer_results/{model_name}_{explainer}_{task_name}_heatmaps.npz\"\n",
    "            if os.path.exists(OUT_PATH):\n",
    "                print(f\"{OUT_PATH} already exists!\")\n",
    "                continue\n",
    "            \n",
    "            print(\"Generating\", OUT_PATH)\n",
    "\n",
    "            # load dataset\n",
    "            if task_name == \"color\":\n",
    "                DATA_PATH           = f'{repo_path}/example_data/dataset_preparation/geometric_shapes/test_colors.npz'\n",
    "            elif task_name == \"rotation\":\n",
    "                DATA_PATH           = f'{repo_path}/example_data/dataset_preparation/geometric_shapes/test_rotation.npz'\n",
    "            elif task_name == \"roundedness\":\n",
    "                DATA_PATH           = f'{repo_path}/lorentz_workshop/dataset_roundedness.npz'\n",
    "            else:\n",
    "                print(\"Wrong task name, aborting: \", task_name)\n",
    "                continue\n",
    "            \n",
    "            data                = prepare_data(DATA_PATH)\n",
    "\n",
    "            if model_name == \"original\":\n",
    "                MODEL_PATH          = Path(f'{repo_path}/lorentz_workshop', \"geometric_shapes_model.onnx\")\n",
    "            elif model_name == \"pytorch\":\n",
    "                MODEL_PATH          = Path(f'{repo_path}/lorentz_workshop', \"pytorch_model.onnx\")\n",
    "            else:\n",
    "                print(\"Wrong model name, aborting: \", model_name)\n",
    "                continue\n",
    "\n",
    "            # Predict with onnx model\n",
    "            onnx_model          = onnx.load(MODEL_PATH)\n",
    "            pred_onnx           = run_model(data['images'], MODEL_PATH)\n",
    "            pred_ids            = pred_onnx.argmax(axis=1)\n",
    "\n",
    "            print(\"Accuracy:\", sum(pred_ids == data['labels']) / len(data['labels']), \"\\n\")\n",
    "\n",
    "\n",
    "            # GENERATE HEATMAPS AND SAVE\n",
    "            hms = []\n",
    "            for i_instance in range(len(pred_ids)):\n",
    "                # select instance for testing\n",
    "                test_sample     = data['images'][i_instance].copy().astype(np.float32)\n",
    "\n",
    "                if explainer == \"lime\":\n",
    "                    relevances      = dianna.explain_image(MODEL_PATH, test_sample,\n",
    "                                                        method=\"LIME\", labels=[pred_ids[i_instance]], nsamples=2000,\n",
    "                                                        n_masks=1000, feature_res=12, p_keep=0.7,\n",
    "                                                        axis_labels=('channels','height','width'))\n",
    "                    grayscale_hm   = relevances[0]\n",
    "                    \n",
    "                elif explainer == \"rise\":\n",
    "                    relevances = dianna.explain_image(MODEL_PATH, test_sample,\n",
    "                                                    method=\"RISE\", labels=[pred_ids[i_instance]], n_masks=10000,\n",
    "                                                    feature_res=8, p_keep=0.8,\n",
    "                                                    axis_labels=('channels', 'height', 'width'))\n",
    "                    grayscale_hm   = relevances[0]\n",
    "                \n",
    "                elif explainer == \"shap\":\n",
    "                    shap_values, segments_slic = dianna.explain_image(MODEL_PATH, test_sample,\n",
    "                                                                    method=\"KernelSHAP\", labels=[0], nsamples=2000,\n",
    "                                                                    n_segments=300, sigma=0.2,\n",
    "                                                                    axis_labels=('channels', 'height', 'width'))\n",
    "                    grayscale_hm = shap_values # TODO: This is not correct!\n",
    "\n",
    "                else:\n",
    "                    print(\"Wrong explainer: \", explainer)\n",
    "                    break\n",
    "\n",
    "                grayscale_hm   = (grayscale_hm - grayscale_hm.min())/(grayscale_hm.max() - grayscale_hm.min() + 10e-7)\n",
    "                hms.append(grayscale_hm.tolist())\n",
    "                \n",
    "                \"\"\"\n",
    "                fig, ax         = plt.subplots(1,3)\n",
    "                ax[0].imshow(relevances[0],cmap='jet')\n",
    "                ax[1].imshow(utils.img_to_array(test_sample[0])/255.,cmap='gray')\n",
    "                ax[2].imshow(utils.img_to_array(test_sample[0]) / 255., cmap='gray')\n",
    "                ax[2].imshow(relevances[0], cmap='jet', alpha=0.4)\n",
    "                plt.title(str(pred_ids[i_instance])+'_'+str(pred_onnx[i_instance,pred_ids[i_instance]]))\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "\n",
    "            hms = np.array(hms)\n",
    "            np.savez(OUT_PATH, heatmaps = hms,\n",
    "                    color=data['color'], \n",
    "                    rotation=data['rotation'],\n",
    "                    roundedness=data['roundedness'],\n",
    "                    data_path = DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_results = []\n",
    "\n",
    "# Now that we have all the heatmaps, we can create all the plots\n",
    "for model_name in [\"pytorch\", \"original\"]:\n",
    "    for explainer in [\"rise\", \"lime\"]: # shap\n",
    "        for task_name in [\"color\", \"rotation\", \"roundedness\"]:\n",
    "            OUT_PATH = f\"{repo_path}/lorentz_workshop/explainer_results/{model_name}_{explainer}_{task_name}_heatmaps.npz\"\n",
    "            print(\"Working on\", OUT_PATH)\n",
    "\n",
    "            # load dataset\n",
    "            if task_name == \"color\":\n",
    "                DATA_PATH           = f'{repo_path}/example_data/dataset_preparation/geometric_shapes/test_colors.npz'\n",
    "            elif task_name == \"rotation\":\n",
    "                DATA_PATH           = f'{repo_path}/example_data/dataset_preparation/geometric_shapes/test_rotation.npz'\n",
    "            elif task_name == \"roundedness\":\n",
    "                DATA_PATH           = f'{repo_path}/lorentz_workshop/dataset_roundedness.npz'\n",
    "            else:\n",
    "                print(\"Nope\")\n",
    "                continue\n",
    "            \n",
    "            data                = prepare_data(DATA_PATH)\n",
    "\n",
    "            # Load the heatmaps\n",
    "            output = np.load(OUT_PATH, allow_pickle=True)\n",
    "\n",
    "            # DIMENSION REDUCTION PLOTS. Taken from dim_red_plots.py\n",
    "            images = data['images']\n",
    "            heatmaps = output['heatmaps']\n",
    "\n",
    "            if len(images.shape) == 4:\n",
    "                embedding_img       = pca(images.reshape(images.shape[0], images.shape[2] * images.shape[3]))\n",
    "            elif len(images.shape) == 3:\n",
    "                embedding_img       = pca(images.reshape(images.shape[0], images.shape[1] * images.shape[2]))\n",
    "\n",
    "            embedding_xai       = pca(heatmaps.reshape(heatmaps.shape[0], heatmaps.shape[1] * heatmaps.shape[2]))\n",
    "\n",
    "            fig, ax                 = plt.subplots(1, 2)\n",
    "            viridis                 = cm.get_cmap('viridis', len(embedding_img))\n",
    "\n",
    "            for i in range(len(embedding_img)):\n",
    "                ax[0].scatter(embedding_img[i, 0], embedding_img[i, 1], c=viridis(i), alpha=0.5)\n",
    "                ax[1].scatter(embedding_xai[i, 0], embedding_xai[i, 1], c=viridis(i), alpha=0.5)\n",
    "            fig.savefig(f\"{repo_path}/lorentz_workshop/explainer_results/{model_name}_{explainer}_{task_name}_dim_red_plots.png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(\"Finished dimension reduction plots.\")\n",
    "\n",
    "\n",
    "            # QI'S PLOTS. Taken from gradcam/read.ipynb\n",
    "            x_values = data[task_name][:100]\n",
    "            heatmaps = torch.tensor(output['heatmaps'])\n",
    "\n",
    "            for distance_function in [\"wasserstein\", \"mse_loss\"]:\n",
    "                for transform_function in [\"minmax\", \"softmax\"]:\n",
    "\n",
    "                    if distance_function == \"wasserstein\":\n",
    "                        metric = wasserstein_distance\n",
    "                    elif distance_function == \"mse_loss\":\n",
    "                        metric = mse_loss\n",
    "\n",
    "                    if transform_function == \"minmax\":\n",
    "                        transform = minmax\n",
    "                    elif transform_function == \"softmax\":\n",
    "                        transform = torch.nn.functional.softmax\n",
    "\n",
    "                    changes = np.zeros(len(heatmaps)-1)\n",
    "                    changes_original = np.zeros(len(output['heatmaps'])-1)\n",
    "                    with torch.no_grad():\n",
    "                        for i in range(len(output['heatmaps'])-1): \n",
    "                            adj_change = metric(\n",
    "                                transform(heatmaps[i+1, ...].flatten()), \n",
    "                                transform(heatmaps[i, ...].flatten()))\n",
    "                            changes[i] = adj_change\n",
    "                            changes_original[i] = metric(transform(heatmaps[i+1, ...].flatten()),\n",
    "                                                        transform(heatmaps[0, ...].flatten()))\n",
    "                            \n",
    "                    sns.lineplot(x=x_values[1:], y=changes)\n",
    "                    plt.xlabel(\"Consecutive changes\")\n",
    "                    plt.ylabel(f\"DF = {distance_function}, TF = {transform_function}\")\n",
    "                    plt.savefig(f\"{repo_path}/lorentz_workshop/explainer_results/{model_name}_{explainer}_{task_name}_consecutive_changes_{distance_function}_{transform_function}.png\")\n",
    "                    plt.close()\n",
    "\n",
    "                    sns.lineplot(x=x_values[1:], y=changes_original)\n",
    "                    plt.xlabel(\"Changes wrt to the original input\")\n",
    "                    plt.ylabel(f\"DF = {distance_function}, TF = {transform_function}\")\n",
    "                    plt.savefig(f\"{repo_path}/lorentz_workshop/explainer_results/{model_name}_{explainer}_{task_name}_original_changes_{distance_function}_{transform_function}.png\")\n",
    "                    plt.close()\n",
    "\n",
    "                    res_kendall = kendalltau(x_values[1:][~np.isnan(changes_original)], changes_original[~np.isnan(changes_original)])\n",
    "                    res_pearson = pearsonr(x_values[1:][~np.isnan(changes_original)], changes_original[~np.isnan(changes_original)])\n",
    "                    statistic_results.append({\"model\": model_name, \"explainer\": explainer, \"change\": task_name, \"df\": distance_function,\n",
    "                                              \"tf\": transform_function, \"kendall_pval\": res_kendall.pvalue, \"kendall_val\": res_kendall.statistic,\n",
    "                                              \"pearson_pval\": res_pearson.pvalue, \"pearson_val\": res_pearson.statistic})\n",
    "                    \n",
    "            print(\"Finished Qi's plots.\")\n",
    "            \n",
    "\n",
    "# Write statistic_results to a html table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(statistic_results)\n",
    "df.index = df.apply(lambda row: f\"{row['model']}_{row['explainer']}_{row['change']}_{row['df']}_{row['tf']}\", axis=1)\n",
    "df = df[['kendall_pval', 'kendall_val', 'pearson_pval', 'pearson_val']]\n",
    "df.to_html(f\"{repo_path}/lorentz_workshop/explainer_results/original_changes_statistics.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exporting the pytorch model to onnx. No need to run this if you already have pytorch_model.onnx\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShapesNet(nn.Module):\n",
    "    def __init__(self, kernels=[8, 16], dropout = 0.2, classes=2):\n",
    "        '''\n",
    "        Two layer CNN model with max pooling.\n",
    "        '''\n",
    "        super(ShapesNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        # 1st layer\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        # 2nd layer\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(kernels[0], kernels[1], kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 16 * kernels[-1], kernels[-1]) # pixel 64 / maxpooling 2 * 2 = 16\n",
    "        self.fc2 = nn.Linear(kernels[-1], classes)\n",
    "\n",
    "    def forward(self, x, mode='train'):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if mode == 'train':\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            return F.softmax(x, dim=1)\n",
    "\n",
    "import os\n",
    "model               = ShapesNet().to('cpu')\n",
    "MODEL_PATH = f'{repo_path}/lorentz_workshop/gradcam/retrain_geometric_shapes_model.pt'\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH))['model_state_dict'])\n",
    "\n",
    "# set the model to inference mode \n",
    "model.eval() \n",
    "\n",
    "# Let's create a dummy input tensor  \n",
    "dummy_input = torch.randn(1, 1,64,64, requires_grad=True)  \n",
    "\n",
    "# Export the model   \n",
    "torch.onnx.export(model,         # model being run \n",
    "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "         f\"{repo_path}/lorentz_workshop/pytorch_model.onnx\",       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         input_names = ['modelInput'],   # the model's input names \n",
    "         output_names = ['modelOutput'], # the model's output names \n",
    "         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes \n",
    "                                'modelOutput' : {0 : 'batch_size'}}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dianna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
