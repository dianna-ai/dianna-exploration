{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for quantitative experiments: text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template is meant as basis for the quantitative text experiments as defined in issues [#474](https://github.com/dianna-ai/dianna/issues/474) and [#481](https://github.com/dianna-ai/dianna/issues/481).\n",
    "\n",
    "It is based on the dianna [text tutorials](https://github.com/dianna-ai/dianna/tree/main/tutorials) for [RISE](https://github.com/dianna-ai/dianna/blob/main/tutorials/rise_text.ipynb) and [LIME](https://github.com/dianna-ai/dianna/blob/main/tutorials/lime_text.ipynb) which are laregely overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena/anaconda3/envs/dianna310-2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-21 16:34:06.779842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 16:34:06.934697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-21 16:34:06.934735: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torchtext.vocab import Vectors\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "import dianna\n",
    "from dianna import visualization\n",
    "from dianna import utils\n",
    "from dianna.utils.tokenizers import SpacyTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model and related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# NOTE: wget is a more generic solution, but for some reason it does a partial download! \n",
    "# SOLUTION: Copying the files in the dianna-exploration repo from dianna repo\n",
    "# pip install wget\n",
    "# import wget \n",
    "#url_model = 'https://zenodo.org/record/5910598/files/movie_review_model.onnx'\n",
    "#url_model = 'https://github.com/dianna-ai/dianna/blob/main/tutorials/models/movie_review_model.onnx'\n",
    "#url_word_vector = 'https://github.com/dianna-ai/dianna/blob/main/tutorials/data/movie_reviews_word_vectors.txt'\n",
    "## first time download\n",
    "#if not(os.path.isfile('movie_review_model.onnx')):\n",
    "#    model_file = wget.download(url_model)\n",
    "#if not(os.path.isfile('movie_reviews_word_vectors.txt')):    \n",
    "#    word_vector_file = wget.download(url_word_vector)\n",
    "\n",
    "model_file = '../models/movie_review_model.onnx'\n",
    "word_vector_file = '../data/movie_reviews_word_vectors.txt'   \n",
    "labels = (\"negative\", \"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable method\n",
    "\n",
    "Here we define the XAI method and it's parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explainer_type = 'RISE'\n",
    "Explainer_type = 'LIME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Explainer_type == 'RISE':\n",
    "    print('Setting up RISE parameters')\n",
    "    # here the default, but editable parameters\n",
    "    n_masks = 1000 # (int) Number of masks to generate.\n",
    "    feature_res = 8 # (int) Resolution of features in masks.\n",
    "    p_keep = None # (float) Fraction of input data to keep in each mask (Default: auto-tune this value).\n",
    "    preprocess_function=None # (callable, optional): Function to preprocess input data with\n",
    "elif Explainer_type == 'LIME':\n",
    "    print('Setting up LIME parameters')\n",
    "    # here the default, but editable parameters\n",
    "    # for the meaning of the parameters and their possible values see the LimeTextExplainer class \n",
    "    # at https://github.com/marcotcr/lime/blob/master/lime/lime_text.py        \n",
    "    kernel_width=25\n",
    "    kernel=None\n",
    "    verbose=False\n",
    "    class_names=None # same as labels in the call of dianna.explain_text()?\n",
    "    feature_selection='auto'\n",
    "    split_expression=r'\\W+'\n",
    "    bow=False\n",
    "    mask_string=None\n",
    "    random_state=None\n",
    "    char_level=False\n",
    "    preprocess_function=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pre-trained Stanford movie reviews model\n",
    "\n",
    "The model (sentiment classifier) is in [ONNX format](https://onnx.ai/). \n",
    "It accepts numerical tokens as input, and outputs a score between 0 and 1, where 0 means the review has a _negative_ sentiment and 1 that it is _positive_.\n",
    "Here we define a class to run the model, which accepts a sentence (i.e. string) as input and returns two classes: negative and positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the tokenizer for english is available\n",
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieReviewsModelRunner:\n",
    "    def __init__(self, model, word_vectors, max_filter_size):\n",
    "        self.run_model = utils.get_function(model)\n",
    "        self.vocab = Vectors(word_vectors, cache=os.path.dirname(word_vectors))\n",
    "        self.max_filter_size = max_filter_size\n",
    "        \n",
    "        self.tokenizer = SpacyTokenizer(name='en_core_web_sm')\n",
    "\n",
    "    def __call__(self, sentences):\n",
    "        # ensure the input has a batch axis\n",
    "        if isinstance(sentences, str):\n",
    "            sentences = [sentences]\n",
    "\n",
    "        output = []\n",
    "        for sentence in sentences:\n",
    "            # tokenize and pad to minimum length\n",
    "            tokens = self.tokenizer.tokenize(sentence)\n",
    "            if len(tokens) < self.max_filter_size:\n",
    "                tokens += ['<pad>'] * (self.max_filter_size - len(tokens))\n",
    "            \n",
    "            # numericalize the tokens\n",
    "            tokens_numerical = [self.vocab.stoi[token] if token in self.vocab.stoi else self.vocab.stoi['<unk>']\n",
    "                                for token in tokens]\n",
    "\n",
    "            # run the model, applying a sigmoid because the model outputs logits, remove any remaining batch axis\n",
    "            pred = float(sigmoid(self.run_model([tokens_numerical])))\n",
    "            output.append(pred)\n",
    "\n",
    "        # output two classes\n",
    "        positivity = np.array(output)\n",
    "        negativity = 1 - positivity\n",
    "        return np.transpose([negativity, positivity])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_file)\n",
    "print(word_vector_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model runner. max_filter_size is a property of the model\n",
    "model_runner = MovieReviewsModelRunner(model_file, word_vector_file, max_filter_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data\n",
    "\n",
    "At the moment only a single sentence review is loaded. For testing this should be a small batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"A delectable and intriguing thriller filled with surprises\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the model with the dianna explainer\n",
    "\n",
    "The simplest way to run DIANNA on text data is with dianna.explain_text. The arguments are:\n",
    "\n",
    "    The function that runs the model (a path to a model in ONNX format is also accepted)\n",
    "    The text we want to explain\n",
    "    The name of the explainable-AI method we want to use (RISE, LIME, etc.)\n",
    "    The numerical indices of the classes we want an explanation for\n",
    "\n",
    "dianna.explain_text returns a list of tuples. Each tuple contains a word, its location in the input text, and its relevance for the selected output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An explanation is returned for each label, but we ask for just one label so the output is a list of length one.\n",
    "\n",
    "if Explainer_type == 'RISE':\n",
    "    print('Explainer type is RISE')\n",
    "    # here the chosen above RISE parameters \n",
    "    explanation_relevances =  dianna.explain_text(model_runner, review, model_runner.tokenizer, Explainer_type,\n",
    "                                              labels=[labels.index('positive')], n_masks = n_masks, \n",
    "                                              feature_res = feature_res, p_keep = p_keep,\n",
    "                                              preprocess_function = preprocess_function)[0]\n",
    "elif Explainer_type == 'LIME':\n",
    "        print('Explainer type is LIME')\n",
    "        # here the chosen above LIME parameters \n",
    "        explanation_relevances =  dianna.explain_text(model_runner, review, model_runner.tokenizer, Explainer_type,\n",
    "                                              labels=[labels.index('positive')], \n",
    "                                              kernel_width= kernel_width, kernel=kernel,verbose=verbose,\n",
    "                                              class_names=class_names, feature_selection=feature_selection,\n",
    "                                              split_expression=split_expression, bow=bow, mask_string=mask_string,\n",
    "                                              random_state=random_state, char_level=char_level,\n",
    "                                              preprocess_function=preprocess_function)[0]\n",
    "        \n",
    "explanation_relevances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIANNA includes a visualization package, capable of highlighting the relevance of each word in the text for a chosen class. Words in favour of the selected class are highlighted in red, while words against the selected class - in blue. The most ir/relevant the word is the darker blue/red the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.highlight_text(explanation_relevances, model_runner.tokenizer.tokenize(review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
